[TOC]

# Binlog与Redo Log

## 1. Binlog

Binlog是MySQL Server层的日志，所有存储引擎都支持该日志，它主要记录原始的SQL语句。在事务执行过程中，先把日志写入binlog cahce，提交时再写入到binlog file。每个线程都会分配一个binlog cache，由参数binlog_cache_size控制大小，超过了则需要暂时缓存到磁盘上，事务提交后会把完整事务写入binlog并清空binlog cache。

binlog是追加写入的，写到一定大小会写入下一个文件中，并不覆盖之前的文件，因此也可以理解为归档日志。由于binlog记录了所有逻辑操作，且文件不会覆盖，因此主要用于MySQL复制实现以及备份恢复，通过binlog可以将数据库恢复到binlog范围内的任意时间点。

```
mysql> show binlog events in 'mysql-bin.000007'\G
*************************** 4. row ***************************
   Log_name: mysql-bin.000007
        Pos: 259
 Event_type: Query
  Server_id: 3307
End_log_pos: 338
       Info: BEGIN
*************************** 5. row ***************************
   Log_name: mysql-bin.000007
        Pos: 338
 Event_type: Rows_query
  Server_id: 3307
End_log_pos: 610
       Info: # INSERT INTO `departments` VALUES
('d001','Marketing'),
('d002','Finance'),
('d003','Human Resources'),
('d004','Production'),
('d005','Development'),
('d006','Quality Management'),
('d007','Sales'),
('d008','Research'),
('d009','Customer Service')
*************************** 6. row ***************************
   Log_name: mysql-bin.000007
        Pos: 610
 Event_type: Table_map
  Server_id: 3307
End_log_pos: 674
       Info: table_id: 225 (employees.departments)
```

二进制日志由参数log-bin控制，我们可以指定其文件路径及文件名格式，生成的index文件为二进制的索引文件，用来存放过往的二进制日志序号。二进制日志记录的信息和行为同时收到下列参数的影响：

- max_binlog_size：指定了单个二进制日志文件的最大值，如果超过该值则生成新的二进制日志文件，序号+1并记录到index文件中。由于单个事务的binlog是不能拆开的，因此可能binlog文件大小可能会超出限制
- binlog_cache_size：系统给binlog分配了一块内存，由参数binlog_cache_size控制单个线程binlog cache的大小，如果超过限制则放到临时文件中，事务提交后则写入binlog并清空binlog cache。通过show global status查看binlog_cache_use和binlog_cache_disk_use的状态，可以判断binlog_cache_size是否设置合理。
- sync_binlog：binlog写入时是先写到文件系统的page cache，并没有持久化到磁盘，等待fsync将数据持久化到磁盘上。这个机制是由参数sync_binlog控制的，为0时表示每次提交事务只写到page cache，不做fsync；为1时每次提交事务都会执行fsync；大于1时则表示每次提交事务写入到page cache，等累计N个事务再fsync，设置为大于1的值可能会在主机异常重启后丢失N个事务的binlog日志
- log-slave-update：如果当前实例在复制中是slave角色，想要将master获取并执行的二进制日志写入自身的二进制日志文件中，需要开启log-slave-update，特别是在级联复制的场景下
- binlog_format：binlog_format影响了记录二进制日志的格式，其有三个可选值：ROW、STATEMENT、MIXED。STATEMENT格式记录的是逻辑SQL语句；ROW格式记录表的行更改情况，导致二进制日志大小变大，RC隔离级别下必须设置为ROW；MIXED格式下，默认采用STATEMENT格式记录二进制日志，在部分情况下会使用ROW格式。

### 1.1 Event



## 2. Redo Log

在一个高并发的OLTP系统中，如果每次DML操作都要从数据文件拉取对应记录修改再回写到数据文件中，这样产生的IO成本和时间成本都太高。因此MySQL采用了WAL(Write-Ahead Logging)机制，即先写日志，再写磁盘。InnoDB将更新记录写到redo log buffer中，然后同步刷新到重做日志文件，这个时候就已经完成了。redo log buffer的大小由参数innodb_log_buffer_size控制，默认为8MB。

重做日志文件大小是固定的，由参数innodb_log_files_in_group控制文件数量，innodb_log_file_size控制文件大小。从头开始写，写到最后再回到第一个文件的开始循环写入

![checkpoint](https://gitee.com/dba_one/wiki_images/raw/master/images/16a7950217b3f0f4ed02db5db59562a7.png)

write pos是当前记录的位置，一边写一边往后移，写道logfile3末尾就从logfile0的开始位置继续写；checkpoint是要擦除的位置，擦除前需要确保脏页数据已经刷新到磁盘中。两者之间的空间就是干净页，可以用于记录新的操作，如果write pos追上checkpoint就表示redo log满了，这时需要先推进checkpoint脏页刷新，因此需要确保redo log file足够大，否则频繁写满会导致性能下降。

对于redo log的写入策略，由参数innodb_flush_log_at_trx_commit控制，它有三个可选值：

- 设置为0：表示每次提交时只将redo log写入redo log buffer中
- 设置为1：表示每次提交时将redo log持久化到磁盘上
- 设置为2：表示每次提交时只将redo log写入到page cache上

除此之外，下列三种情况下也会将redo log buffer中的内容持久化到磁盘中：

- Master Thread每一秒将重做日志缓冲刷新到重做日志文件
- 每个事务提交时会将重做日志缓冲刷新到重做日志文件
- 当重做日志缓冲池空间小于1/2时，重做日志缓冲会刷新到重做日志文件

> 需要注意的是，事务在执行过程中也会将redo写入redo log buffer中，从而被持久化到磁盘上

### 2.1. checkpoint

Checkpoint用于解决下列几个问题：

- 缩短数据库的恢复时间。
- 缓冲池不够用时，将内存中的脏页刷新到磁盘中
- 重做日志不可用时，刷新脏页

对于InnoDB而言，其是通过LSN(Log Sequence Number)来标记版本的，LSN由8个字节的数字组成，每个页有LSN，重做日志也有LSN，Checkpoint也有LSN

```
---
LOG
---
Log sequence number 12233084271098
Log flushed up to   12233084270970
Pages flushed up to 12232939243084
Last checkpoint at  12232939162280
```

**sharp Checkpoint与Fuzzy Checkpoint**

在Innodb引擎内部，有两种checkpoint，分别为sharp Checkpoint和Fuzzy Checkpoint。Sharp发生在数据库关闭时将所有脏页都刷新回磁盘，而Fuzzy则为每次都只刷新部分脏页，触发Fuzzy checkpoint有下面几种情况：

- Master Thread以每秒或每10秒的速度从缓冲池的脏页列表中刷新一定比例的页到磁盘中，这个过程是异步进行的。
- Innodb需要保证LRU列表中有一定的空闲页可供使用，如果不满足就需要从LRU尾端释放页，如果是脏页就需要进行checkpoint。检查由Page Cleaner线程进行，用户可以通过参数innodb_lru_scan_depth控制LRU可用页的数量，默认为1024
- 重做日志文件不可用的情况下，需要强制将一些页刷回磁盘，页是从脏页列表中选取。若将已经写入到重做日志的LSN记为redo_lsn，将已刷新回磁盘最新页的LSN记为checkpoint_lsn，则定义
  checkpoint_age = redo_lsn - checkpoint_lsn
  再定义以下变量：
  async_water_mark = 75% * total_redo_log_file_size
  sync_water_mark = 90% * total_redo_log_file_size
  若每个重做日志文件大小为1G，有2个重做日志文件，则重做日志大小为2G，那么async_water_mark=1.5G，sync_water_mark=1.8G，则当checkpoint_age<async_water_mark时，不需要刷新任何脏页到磁盘；当async_water_mark<checkpoint_age<sync_water_mark时触发Async Flush，从脏页列表刷新足够的脏页回磁盘，使得满足checkpoint_age<async_water_mark
- 当脏页比例超过参数innodb_max_dirty_pages_pct时，强制推进checkpoint，默认为75%。当前脏页比例通过算法得到一个0-100的值，当前日志序号与checkpoint序号的差值通过算法得到一个0-100的值记，取二者其中的最大值记为R，刷脏页的速度就等于innodb_io_capacity乘以R%。当前脏页比例可通过innodb_buffer_pool_pages_dirty/innodb_buffer_pool_pages_total计算

控制脏页刷盘策略，首先要告诉Innodb磁盘IO的能力，刷脏页的时候能有多快，通过参数innodb_io_capacity来设置，建议设置为磁盘的IOPS。可以通过fio工具来测试磁盘IOPS

```
$ fio -filename=/service/iotest -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest
```

### 2.2. Crash-Safe

在Innodb引擎中，Redo log能够在实例崩溃或异常重启时，保证已提交的记录不会丢失，这种能力称之为crash-safe。因此建议将参数innodb_flush_log_at_trx_commit设置为1，确保每个事务的redo log持久化到磁盘



## 3. 2PC

为了确保binlog和redo log之间的逻辑一致性，引入了两阶段提交(2PC)的过程，在数据更新之后先写入redo log并处于prepare阶段，再写入binlog，binlog写入完成后commit整个事务.

![Insert 2PC](https://gitee.com/dba_one/wiki_images/raw/master/images/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

在commit阶段实际会分为三个步骤：

1. Innodb redo prepare：写入redo log，并记录事务XID
2. Writer binary log：写入binlog，并记录事务XID
3. Innodb commit log：写入提交日志

![commit](https://gitee.com/dba_one/wiki_images/raw/master/images/e401613e9f10378e2f6739400c863853.png)

当前两步完成时，即使第三步未写入成功，该事务也会在启动时通过XID做recover来提交该事务，以确保redo log和binlog一致。

## 4. Group Commit

出于安全考虑通常会将innodb_flush_log_at_trx_commit设置为1，意味着每次提交就要刷一次盘，对于大并发场景可能会出现瓶颈，特别是HDD环境。组提交的优化思想就是多个事务合并为一个刷盘动作。由于在InnoDB中LSN是单调递增的，假设现在有事务TRX1、TRX2、TRX3对应LSN1、LSN2、LSN3，其中LSN1<LSN2<LSN3，当它们同时提交时，TRX3获取到log_mutex锁进行刷盘，同时会将小于它的TRX1和TRX2一起刷盘。

![redo group commit](https://gitee.com/dba_one/wiki_images/raw/master/images/933fdc052c6339de2aa3bf3f65b188cc.png)

在5.6之前，开启binlog后无法进行group commit，由于prepare_commit_mutex的问题导致redo和binlog写入完全串行化，性能急剧下降。后续Mariadb就提出了一个Binlog Group Commit方案，即在准备写入Binlog时，维持一个队列，最早进入队列的是leader，后来的是follower，leader为搜集到的队列中的线程依次写Binlog文件, 并commit事务。MySQL5.6开始也支持binlog group commit，其将group commit的过程分为了三个阶段：

- flush阶段： redo log的组提交
  1. 获取队列中的一组事务
  2. 将redo log中prepare阶段的数据刷盘
  3. 将binlog写入page cache
- sync阶段：binlog的组提交
  1.  将一组binlog  fsync落盘
  2. 为了增加事务组中事务的数量，由两个参数控制获取事务队列的时机：binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count，前者为等待时间，后者为等待事务数量
- commit：为各个线程做引擎层的事务commit
  1. 遍历队列中的事务，进行innodb commit
  2. 唤醒队列中等待的线程

 **组提交优化**

从2PC的恢复逻辑中，可以发现原则上只要保证prepare的redo log在写binlog之前完成就不会造成影响。为了让redo log一次fsync能够带更多的事务，优化将redo log的fsync步骤移动到binlog 写入I/O cache之后，通过延迟写redo log的方式，显式的为redo log做了一次组写入，并减少了log_sys->mutex的竞争。

![组提交优化](https://gitee.com/dba_one/wiki_images/raw/master/images/5ae7d074c34bc5bd55c82781de670c28.png)

目前该优化已经被MySQL5.7.6应用了该优化思路

```
When using InnoDB with binary logging enabled, concurrent transactions written in the InnoDB redo log are now grouped together before synchronizing 
to disk when innodb_flush_log_at_trx_commit is set to 1, which reduces the amount of synchronization operations. This can lead to improved performance.
```

[MySQL · 性能优化· Group Commit优化]:http://mysql.taobao.org/monthly/2015/01/01/
[MySQL45讲：MySQL是怎么保证数据不丢的？]:https://time.geekbang.org/column/article/76161

