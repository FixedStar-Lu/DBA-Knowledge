[TOC]

---

>当发生数据异常时，如果没有有效备份并且没有开启binlog时，需要通过一些特殊的方式来找回数据，但这种方式还是会存在丢失数据的可能，仅用在极端情况下的数据恢复，还是强烈建议定期做数据库备份并进行恢复演练验证

## undrop-for-innodb

undrop-for-innodb是针对MySQL Innodb的数据恢复工具，其会通过扫描文件或磁盘设备，解析innodb数据页来恢复丢失的数据，对于DDL误删除表或磁盘损坏等情况很有帮助。项目地址：[undrop-for-innodb](https://github.com/twindb/undrop-for-innodb)

### 安装配置

**解压安装**
```
[root@t-luhx03-v-szzb mysql]# unzip undrop-for-innodb-develop.zip 
[root@t-luhx03-v-szzb mysql]# mv undrop-for-innodb-develop /usr/local/undrop
[root@t-luhx03-v-szzb mysql]# cd /usr/local/undrop
[root@t-luhx03-v-szzb undrop]# make
```

**目录说明**

- dictionary：存放数据字典sql脚本
- sakila：测试用的schema
- stream_parser：可执行文件，用于扫描磁盘或磁盘设备，找出innodb数据页，按照index_id进行组织
- c_parser：可执行文件，用于解析innodb数据页，找出行记录
- sys_parser：可执行文件，通过字典表恢复表结构

**创建测试表**
```
root@test 13:57:  desc t1;
+-------+---------+------+-----+---------+-------+
| Field | Type    | Null | Key | Default | Extra |
+-------+---------+------+-----+---------+-------+
| id    | int(11) | NO   | PRI | NULL    |       |
| a     | int(11) | YES  | MUL | NULL    |       |
| b     | int(11) | YES  |     | NULL    |       |
+-------+---------+------+-----+---------+-------+
3 rows in set (0.01 sec)

root@test 14:11:  checksum table t1;
+---------+------------+
| Table   | Checksum   |
+---------+------------+
| test.t1 | 3888021100 |
+---------+------------+
1 row in set (0.00 sec)

root@test 14:11:  select count(*) from t1;
+----------+
| count(*) |
+----------+
|      100 |
+----------+
1 row in set (0.00 sec)
```

**删除测试表**
```
root@test 14:12:  drop table t1;
Query OK, 0 rows affected (0.05 sec)
```

### 解析表空间数据文件

**分析tablespace**
```
[root@t-luhx03-v-szzb undrop]# ./stream_parser -f /service/mysql/data/ibdata1 
Opening file: /service/mysql/data/ibdata1
File information:

ID of device containing file:        64770
inode number:                      3407887
protection:                         100640 (regular file)
number of hard links:                    1
user ID of owner:                     1012
group ID of owner:                    1007
device ID (if special file):             0
blocksize for filesystem I/O:         4096
number of blocks allocated:        2097160
time of last access:            1592374456 Wed Jun 17 14:14:16 2020
time of last modification:      1592374457 Wed Jun 17 14:14:17 2020
time of last status change:     1592374457 Wed Jun 17 14:14:17 2020
total size, in bytes:           1073741824 (1.000 GiB)

Size to process:                1073741824 (1.000 GiB)
Worker(0): 5.47% done. 2020-06-17 14:21:15 ETA(in 00:00:20). Processing speed: 48.000 MiB/sec
Worker(0): 30.47% done. 2020-06-17 14:20:58 ETA(in 00:00:02). Processing speed: 256.000 MiB/sec
Worker(0): 54.69% done. 2020-06-17 14:20:58 ETA(in 00:00:01). Processing speed: 248.000 MiB/sec
Worker(0): 78.12% done. 2020-06-17 14:20:58 ETA(in 00:00:00). Processing speed: 240.000 MiB/sec
All workers finished in 4 sec
```
执行完成会生成一个pages-ibdata1目录，子目录分为索引页和blob页，我们需要的内容在索引页中

```
[root@t-luhx03-v-szzb FIL_PAGE_INDEX]# ls -lrt
total 288
-rw-r----- 1 root root 16384 Jun 17 14:20 18446744069414584320.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000004.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000003.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000017.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000014.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000013.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000012.page
-rw-r----- 1 root root 16384 Jun 17 14:20 0000000000000011.page
-rw-r----- 1 root root 32768 Jun 17 14:20 0000000000000002.page
-rw-r----- 1 root root 32768 Jun 17 14:20 0000000000000001.page
-rw-r----- 1 root root 32768 Jun 17 14:20 0000000000000016.page
-rw-r----- 1 root root 32768 Jun 17 14:20 0000000000000015.page
-rw-r----- 1 root root 32768 Jun 17 14:20 0000000000000005.page
```

所有字典表的index_id是硬编码的，01对应SYS_TABLES，02对应SYS_COLUMNS，03对应SYS_INDEXES，04对应SYS_FILEDS

**解析page**
```
[root@t-luhx03-v-szzb undrop]# mkdir dumps/default
[root@t-luhx03-v-szzb undrop]# ./c_parser -4Df pages-ibdata1/FIL_PAGE_INDEX/0000000000000001.page -t dictionary/SYS_TABLES.sql >./dumps/default/SYS_TABLES  2>./dumps/default/SYS_TABLES.sql
[root@t-luhx03-v-szzb undrop]# ./c_parser -4Df pages-ibdata1/FIL_PAGE_INDEX/0000000000000003.page -t dictionary/SYS_INDEXES.sql  >./dumps/default/SYS_INDEXES  2>./dumps/default/SYS_INDEXES.sql
[root@t-luhx03-v-szzb undrop]# ./c_parser -4Df pages-ibdata1/FIL_PAGE_INDEX/0000000000000002.page -t dictionary/SYS_COLUMNS.sql >./dumps/default/SYS_COLUMNS  2>./dumps/default/SYS_COLUMNS.sql
[root@t-luhx03-v-szzb undrop]# ./c_parser -4Df pages-ibdata1/FIL_PAGE_INDEX/0000000000000004.page -t dictionary/SYS_FIELDS.sql >./dumps/default/SYS_FIELDS  2>./dumps/default/SYS_FIELDS.sql
```
参数中的4DF中的4表示文件格式是REDUNDANT，系统表的默认格式；D表示只恢复删除的记录；f后面跟对应的page


**拷贝dictionary和dumps目录拷贝到异机**
```
[root@t-luhx03-v-szzb undrop]# scp -r dumps @10.0.139.161:/usr/local/undrop/
[root@t-luhx03-v-szzb undrop]# scp -r dictionary/ @10.0.139.161:/usr/local/undrop/
```

### 恢复表结构

**恢复数据字典(需要开启LOAD DATA)**
```
root@(none) 14:55:  create database recover;
Query OK, 1 row affected (0.01 sec)

root@(none) 14:56:  use recover
Database changed

root@recover 14:57:  source /usr/local/undrop/dictionary/SYS_TABLES.sql

root@recover 14:57:  source /usr/local/undrop/dictionary/SYS_INDEXES.sql

root@recover 14:57:  source /usr/local/undrop/dictionary/SYS_FIELDS.sql

root@recover 14:57:  source /usr/local/undrop/dictionary/SYS_COLUMNS.sql

root@recover 15:08:  source /usr/local/undrop/dumps/default/SYS_TABLES.sql
Query OK, 0 rows affected (0.00 sec)

Query OK, 2 rows affected, 1 warning (0.00 sec)
Records: 2  Deleted: 0  Skipped: 0  Warnings: 1

root@recover 15:08:  source /usr/local/undrop/dumps/default/SYS_INDEXES.sql
Query OK, 0 rows affected (0.00 sec)

Query OK, 2 rows affected, 1 warning (0.00 sec)
Records: 2  Deleted: 0  Skipped: 0  Warnings: 1

root@recover 15:09:  source /usr/local/undrop/dumps/default/SYS_COLUMNS.sql
Query OK, 0 rows affected (0.00 sec)

Query OK, 6 rows affected, 1 warning (0.00 sec)
Records: 6  Deleted: 0  Skipped: 0  Warnings: 1

root@recover 15:09:  source /usr/local/undrop/dumps/default/SYS_FIELDS.sql
Query OK, 0 rows affected (0.00 sec)

Query OK, 2 rows affected, 1 warning (0.00 sec)
Records: 2  Deleted: 0  Skipped: 0  Warnings: 1
```

**编译sys_parser生成DDL语句**
```
[root@t-luhx01-v-szzb undrop]# make sys_parser
[root@t-luhx01-v-szzb undrop]# ./sys_parser -h127.0.0.1  -uroot  -p'Abcd123#' -d recover  test/t1
CREATE TABLE `t1`(
	`id` INT NOT NULL,
	`a` INT,
	`b` INT,
	PRIMARY KEY (`id`)
) ENGINE=InnoDB;
```

### 恢复数据

如果开启了innodb_file_per_table，表对应的ibd表空间文件会被删除，此时需要扫描整个磁盘，需确保磁盘没有数据写入防止数据页被覆盖
```
[root@t-luhx03-v-szzb undrop]# ./stream_parser -f /dev/mapper/dbvg-dblv -t 2G -t 100G
Opening file: /dev/mapper/dbvg-dblv
File information:

ID of device containing file:            5
inode number:                        15546
protection:                          60660 (block device)
number of hard links:                    1
user ID of owner:                        0
group ID of owner:                       6
device ID (if special file):         64770
blocksize for filesystem I/O:         4096
number of blocks allocated:              0
time of last access:            1592352002 Wed Jun 17 08:00:02 2020
time of last modification:      1573539555 Tue Nov 12 14:19:15 2019
time of last status change:     1573539555 Tue Nov 12 14:19:15 2019
total size, in bytes:                    0 (0.000 exp(+0))

Size to process:              107374182400 (100.000 GiB)
Worker(0): 1.02% done. 2020-06-17 15:51:27 ETA(in 00:06:32). Processing speed: 257.984 MiB/sec
Worker(0): 2.02% done. 2020-06-17 15:53:06 ETA(in 00:08:06). Processing speed: 206.394 MiB/sec
Worker(0): 3.03% done. 2020-06-17 15:54:44 ETA(in 00:09:38). Processing speed: 171.717 MiB/sec
```

执行完成后会在pages-dbvg-dblv/FIL_PAGE_INDEX下生成page文件，查找表对应的INDEX_ID
```
root@recover 15:55:  select * from sys_indexes;
+----------+----+---------+----------+------+-------+------------+
| TABLE_ID | ID | NAME    | N_FIELDS | TYPE | SPACE | PAGE_NO    |
+----------+----+---------+----------+------+-------+------------+
|       44 | 49 | PRIMARY |        1 |    3 |    32 | 4294967295 |
|       44 | 50 | a       |        1 |    0 |    32 | 4294967295 |
+----------+----+---------+----------+------+-------+------------+
2 rows in set (0.00 sec)

root@recover 15:55:  select * from sys_tables;
+---------+----+--------+------+--------+---------+--------------+-------+
| NAME    | ID | N_COLS | TYPE | MIX_ID | MIX_LEN | CLUSTER_NAME | SPACE |
+---------+----+--------+------+--------+---------+--------------+-------+
| test/t1 | 44 |      3 |   33 |      0 |      80 |              |    32 |
+---------+----+--------+------+--------+---------+--------------+-------+
```

上面可以看到我需要的就是INDEX_ID为49的page，将表结构创建语句写入/tmp/t1.sql，通过c_parser来导出数据
```

[root@t-luhx03-v-szzb undrop]# ./c_parser -6f pages-dbvg-dblv/FIL_PAGE_INDEX/0000000000000049.page -t /tmp/t1.sql > ./dumps/default/t1 2> ./dumps/default/t1_load.sql
```

**恢复表数据**
```
root@recover 16:21:  source /tmp/t1.sql
Query OK, 0 rows affected (0.18 sec)

root@recover 16:22:  set global local_infile=1;
Query OK, 0 rows affected (0.00 sec)

root@recover 16:23:  source /usr/local/undrop/dumps/default/t1.sql
Query OK, 0 rows affected (0.00 sec)

Query OK, 730 rows affected, 1 warning (0.02 sec)
Records: 420  Deleted: 310  Skipped: 0  Warnings: 1

root@recover 16:30:  select count(*) from t1;
+----------+
| count(*) |
+----------+
|      100 |
+----------+
1 row in set (0.00 sec)

root@recover 16:30:  checksum table t1;
+------------+------------+
| Table      | Checksum   |
+------------+------------+
| recover.t1 | 3888021100 |
+------------+------------+
```

## percona-data-recovery-tool-for-innodb

Percona Data Recovery Tool for InnoDB是Percona提供针对innodb或者xtradb引擎进行数据恢复的工具

**工具特点**

- 支持innodb和xtradb，不支持myisam
- 利用数据文件进行恢复，数据库可处于关闭状态
- 不能保证数据一定可恢复，如果数据块被覆盖则不可恢复

**原理解析**

Innodb数据是以索引的方式组织的，所有数据都是存在16K的数据块中。恢复将所有数据文件分成单个16K的页面，根据每个页面标记的起始点开始匹配，如果与表定义的size合适，则认为匹配成功输出记录

### 安装配置

**下载工具**
[DownLoad Percona data recovery tool](https://launchpadlibrarian.net/78359944/percona-data-recovery-tool-for-innodb-0.5.tar.gz)

**安装依赖**
```
$ yum install ncurses-devel glibc-static perl-DBD-MySQL -y
```

**编译工具**
```
$ ./mysql-source/configure
$ make
```

### 恢复测试

**模拟删除数据**
```
root@test 11:19:  select * from tab1;
+----+------------+
| id | name       |
+----+------------+
|  1 | lu         |
|  2 | heng       |
|  3 | xing       |
|  4 | luhengxing |
+----+------------+

root@test 11:19:  truncate table tab1;
Query OK, 0 rows affected (0.10 sec)
```

**切分页**

>InnoDB页的默认大小是16K，每个页属于一个特定表中的一个特定的index。page_parser工具通过读取数据文件，根据页头中的index ID，拷贝每个页到一个单独的文件中
```
$ ./page_parser -5 -f /service/mysql/data/ibdata1
Opening file: /service/mysql/data_bak/ibdata1:
64770           ID of device containing file
3407879         inode number
33184           protection
1               number of hard links
0               user ID of owner
0               group ID of owner
0               device ID (if special file)
1073741824              total size, in bytes
4096            blocksize for filesystem I/O
2097160         number of blocks allocated
1575516411      time of last access
1575516414      time of last modification
1575516414      time of last status change
1073741824      Size to process in bytes
104857600       Disk cache size in bytes
1.00% done. 2019-12-05 11:32:15 ETA(in 00:01 hours). Processing speed: 10737419 B/sec
3.05% done. 2019-12-05 11:31:25 ETA(in 00:00 hours). Processing speed: 21959752 B/sec
5.18% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22869596 B/sec
7.30% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22856188 B/sec
9.43% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22878566 B/sec
11.27% done. 2019-12-05 11:31:30 ETA(in 00:00 hours). Processing speed: 19698493 B/sec
13.40% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22891353 B/sec
15.47% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22182604 B/sec
17.60% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22946649 B/sec
19.53% done. 2019-12-05 11:31:27 ETA(in 00:00 hours). Processing speed: 20661813 B/sec
21.51% done. 2019-12-05 11:31:26 ETA(in 00:00 hours). Processing speed: 21251019 B/sec
23.64% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22846196 B/sec
25.77% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22879397 B/sec
27.90% done. 2019-12-05 11:31:23 ETA(in 00:00 hours). Processing speed: 22878220 B/sec
29.77% done. 2019-12-05 11:31:28 ETA(in 00:00 hours). Processing speed: 20081073 B/sec
31.88% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22741681 B/sec
34.01% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22834734 B/sec
36.14% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22853565 B/sec
38.26% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22812801 B/sec
40.11% done. 2019-12-05 11:31:28 ETA(in 00:00 hours). Processing speed: 19807987 B/sec
42.24% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22903891 B/sec
44.37% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22847973 B/sec
46.50% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22874206 B/sec
48.63% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22855972 B/sec
50.35% done. 2019-12-05 11:31:29 ETA(in 00:00 hours). Processing speed: 18515758 B/sec
52.44% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22411303 B/sec
54.54% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22540107 B/sec
56.67% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22834205 B/sec
58.58% done. 2019-12-05 11:31:26 ETA(in 00:00 hours). Processing speed: 20594776 B/sec
60.56% done. 2019-12-05 11:31:25 ETA(in 00:00 hours). Processing speed: 21194692 B/sec
62.68% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22828968 B/sec
64.81% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22824780 B/sec
66.93% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22790007 B/sec
68.91% done. 2019-12-05 11:31:25 ETA(in 00:00 hours). Processing speed: 21208919 B/sec
71.04% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22853378 B/sec
73.16% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22784025 B/sec
75.29% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22845096 B/sec
77.42% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22869912 B/sec
79.47% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22074113 B/sec
81.60% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22866712 B/sec
83.72% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22787570 B/sec
85.85% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22844781 B/sec
87.88% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 21750695 B/sec
89.99% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22689534 B/sec
92.11% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22809100 B/sec
94.22% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22602229 B/sec
96.35% done. 2019-12-05 11:31:24 ETA(in 00:00 hours). Processing speed: 22877629 B/sec

$ ls -l pages-1575516636/
total 8
drwxr-x--- 17 root root 4096 Dec  5 11:30 FIL_PAGE_INDEX
drwxr-x---  2 root root 4096 Dec  5 11:30 FIL_PAGE_TYPE_BLOB
```
参数-5表示row format为COMPACT格式，适用于MySQL 5.0之后；-f则是要解析的数据文件

**选择index_id**

通常建议选择主键。如果数据库仍处于运行状态，并且表没有被drop掉，MySQL 5.7之前可以通过Innodb Tablespace Monitor来获取表上的index_id，如果是5.7及之后的版本可以通过下列语句查询
```
mysql> select t.name as table_name,i.name as index_name,index_id from information_schema.INNODB_SYS_TABLES t,information_schema.INNODB_SYS_INDEXES i where t.table_id=i.table_id and t.name='test/tab1';
+------------+------------+----------+
| table_name | index_name | index_id |
+------------+------------+----------+
| test/tab1  | PRIMARY    |       50 |
+------------+------------+----------+
```
该表主键INDEX ID为50，因此需要恢复的INNODB页在0-50子目录下

**生成表DDL**
```
./create_defs.pl --user=root --password='Abcd123#' --port=33006 --db=test --table=tab2 >include/table_defs.h
```

**编译constraints_parser工具**
```
$ make
```

**合并page**
```
$ find pages-1575526210/FIL_PAGE_INDEX/0-50/ -type f -name '*.page' | sort -n | xargs cat > pages-1575526210/FIL_PAGE_INDEX/0-50/customer_pages
```

**恢复数据**
```
$ ./constraints_parser -5 -f pages-1575526210/FIL_PAGE_INDEX/0-50/customer_pages > recovery.sql
LOAD DATA INFILE '/media/mysql/percona-data-recovery-tool-for-innodb-0.5/dumps/default/tab1' REPLACE INTO TABLE `tab1` FIELDS TERMINATED BY '\t' OPTIONALLY ENCLOSED BY '"' LINES STARTING BY 'tab1\t' (id, na
me);

$ more recovery.sql
tab1    1       "lu"
tab1    2       "heng"
tab1    3       "xing"
tab1    4       "luhengxing"
```

**加载数据**
```
$ chown -R mysql.mysql recovery.sql

root@test 14:43:  LOAD DATA INFILE '/media/mysql/percona-data-recovery-tool-for-innodb-0.5/recovery.sql' REPLACE INTO TABLE `tab1` FIELDS TERMINATED BY '\t' OPTIONALLY ENCLOSED BY '"' LINES STARTING BY 'tab
1\t' (id, name);

root@test 14:43:  select * from tab1;
+----+------------+
| id | name       |
+----+------------+
|  1 | lu         |
|  2 | heng       |
|  3 | xing       |
|  4 | luhengxing |
+----+------------+
```

> "ERROR 1290 (HY000): The MySQL server is running with the –secure-file-priv option so it cannot execute this statement"错误需要配置secure_file_priv参数

更多内容可参考：[Percona Data Recovery Tool 单表恢复](https://www.cnblogs.com/gomysql/p/3586822.html)